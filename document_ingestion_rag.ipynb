{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Document Ingestion and Chunking for RAG with Docling\n",
        "\n",
        "This notebook demonstrates how to use **Docling** to ingest, parse, and chunk documents (PDF, DOCX, PPTX) for Retrieval Augmented Generation (RAG) systems.\n",
        "\n",
        "## Overview\n",
        "\n",
        "**Docling** is a powerful document processing library that:\n",
        "- Extracts structured content from various document formats\n",
        "- Preserves document layout and hierarchy (headings, sections, tables)\n",
        "- Provides rich metadata (page numbers, document structure)\n",
        "- Prepares content for embedding and vector database indexing\n",
        "\n",
        "## Workflow Steps\n",
        "\n",
        "1. **Install Dependencies** - Set up Docling and required libraries\n",
        "2. **Document Ingestion** - Load and convert documents using DocumentConverter\n",
        "3. **Structure Extraction** - Parse and access document elements with metadata\n",
        "4. **Chunking Strategy** - Split content intelligently while preserving context\n",
        "5. **Output Preparation** - Export chunks with metadata for embedding\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- PDF, DOCX, or PPTX documents you want to process\n",
        "- Python 3.8+\n",
        "- Jupyter Notebook environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "First, install the required libraries. Docling provides comprehensive document processing capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yashpatil/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Docling imports\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n",
        "from docling.chunking import HybridChunker\n",
        "\n",
        "print(\"✓ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Document Ingestion\n",
        "\n",
        "Now we'll set up the DocumentConverter and configure it to process various document types.\n",
        "\n",
        "### Configuration Options\n",
        "\n",
        "- **OCR**: Enable for scanned documents or images\n",
        "- **Table Extraction**: Use TableFormer for accurate table parsing\n",
        "- **Pipeline Options**: Configure PDF processing behavior\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ DocumentConverter initialized successfully!\n",
            "  - OCR enabled: False\n",
            "  - Table extraction: True\n",
            "  - Table mode: TableFormerMode.ACCURATE\n"
          ]
        }
      ],
      "source": [
        "# Configure the document converter with pipeline options\n",
        "# This setup optimizes for accurate extraction with table support\n",
        "\n",
        "pipeline_options = PdfPipelineOptions()\n",
        "pipeline_options.do_ocr = False  # Set to True for scanned documents\n",
        "pipeline_options.do_table_structure = True  # Enable table extraction\n",
        "pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE  # or FAST for speed\n",
        "\n",
        "# Initialize the DocumentConverter\n",
        "doc_converter = DocumentConverter(\n",
        "    format_options={\n",
        "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"✓ DocumentConverter initialized successfully!\")\n",
        "print(f\"  - OCR enabled: {pipeline_options.do_ocr}\")\n",
        "print(f\"  - Table extraction: {pipeline_options.do_table_structure}\")\n",
        "print(f\"  - Table mode: {pipeline_options.table_structure_options.mode}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Processing a Single Document\n",
        "\n",
        "Provide the path to your document (PDF, DOCX, or PPTX).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing document: /Users/yashpatil/Developer/AI/SunnySavita/Persona.pptx\n",
            "This may take a moment depending on document size...\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/yashpatil/Developer/AI/SunnySavita/Persona.pptx'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/docling_core/utils/file.py:70\u001b[39m, in \u001b[36mresolve_source_to_stream\u001b[39m\u001b[34m(source, headers)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     http_url: AnyHttpUrl = \u001b[43mTypeAdapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAnyHttpUrl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# make all header keys lower case\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/pydantic/type_adapter.py:441\u001b[39m, in \u001b[36mTypeAdapter.validate_python\u001b[39m\u001b[34m(self, object, strict, extra, from_attributes, context, experimental_allow_partial, by_alias, by_name)\u001b[39m\n\u001b[32m    436\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    437\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    438\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    439\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperimental_allow_partial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mValidationError\u001b[39m: 1 validation error for function-wrap[wrap_val()]\n  Input should be a valid URL, relative URL without a base [type=url_parsing, input_value='/Users/yashpatil/Develop...unnySavita/Persona.pptx', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.12/v/url_parsing",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mThis may take a moment depending on document size...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Uncomment the lines below when you have a document ready\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mdoc_converter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m doc = result.document\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(doc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/docling/document_converter.py:237\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    219\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    221\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    228\u001b[39m ) -> ConversionResult:\n\u001b[32m    229\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    230\u001b[39m         source=[source],\n\u001b[32m    231\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m         page_range=page_range,\n\u001b[32m    236\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/docling/document_converter.py:260\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    257\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    259\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/docling/document_converter.py:310\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert\u001b[39m(\n\u001b[32m    306\u001b[39m     \u001b[38;5;28mself\u001b[39m, conv_input: _DocumentConversionInput, raises_on_error: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    307\u001b[39m ) -> Iterator[ConversionResult]:\n\u001b[32m    308\u001b[39m     start_time = time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunkify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconv_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_to_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdoc_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass format_options\u001b[39;49;00m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_log\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGoing to convert document batch...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_func\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/docling/utils/utils.py:15\u001b[39m, in \u001b[36mchunkify\u001b[39m\u001b[34m(iterator, chunk_size)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(iterator, List):\n\u001b[32m     14\u001b[39m     iterator = \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Take the first element from the iterator\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/docling/datamodel/document.py:275\u001b[39m, in \u001b[36m_DocumentConversionInput.docs\u001b[39m\u001b[34m(self, format_options)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdocs\u001b[39m(\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    271\u001b[39m     format_options: Mapping[InputFormat, \u001b[33m\"\u001b[39m\u001b[33mBaseFormatOption\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    272\u001b[39m ) -> Iterable[InputDocument]:\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.path_or_stream_iterator:\n\u001b[32m    274\u001b[39m         obj = (\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m             \u001b[43mresolve_source_to_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    276\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    277\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m item\n\u001b[32m    278\u001b[39m         )\n\u001b[32m    279\u001b[39m         \u001b[38;5;28mformat\u001b[39m = \u001b[38;5;28mself\u001b[39m._guess_format(obj)\n\u001b[32m    280\u001b[39m         backend: Type[AbstractDocumentBackend]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/docling_core/utils/file.py:116\u001b[39m, in \u001b[36mresolve_source_to_stream\u001b[39m\u001b[34m(source, headers)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    115\u001b[39m     local_path = TypeAdapter(Path).validate_python(source)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     stream = BytesIO(\u001b[43mlocal_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    117\u001b[39m     doc_stream = DocumentStream(name=local_path.name, stream=stream)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/pathlib.py:1050\u001b[39m, in \u001b[36mPath.read_bytes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1046\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1047\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[33;03m    Open the file in bytes mode, read it, and close the file.\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1050\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   1051\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m f.read()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/AI/SunnySavita/.conda/lib/python3.11/pathlib.py:1044\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1043\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m io.open(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/yashpatil/Developer/AI/SunnySavita/Persona.pptx'"
          ]
        }
      ],
      "source": [
        "# Specify the path to your document\n",
        "# Replace with your actual document path\n",
        "document_path = \"/Users/yashpatil/Developer/AI/SunnySavita/Persona.pptx\"  # Can be .pdf, .docx, .pptx\n",
        "\n",
        "# Convert the document\n",
        "print(f\"Processing document: {document_path}\")\n",
        "print(\"This may take a moment depending on document size...\")\n",
        "\n",
        "# Uncomment the lines below when you have a document ready\n",
        "result = doc_converter.convert(document_path)\n",
        "doc = result.document\n",
        "print(doc)\n",
        "# Print document content\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DOCUMENT CONTENT\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Export as markdown for readable output\n",
        "markdown_content = doc.export_to_markdown()\n",
        "print(markdown_content)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"Document processed successfully!\")\n",
        "print(f\"Total pages: {len(doc.pages) if hasattr(doc, 'pages') else 'N/A'}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Batch Processing Multiple Documents\n",
        "\n",
        "Process multiple documents at once for efficient pipeline execution.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-10 01:03:33,124 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
            "2025-11-10 01:03:33,153 - INFO - Going to convert document batch...\n",
            "2025-11-10 01:03:33,154 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4a89bda5a26a77cb2b7befc50a30d131\n",
            "2025-11-10 01:03:33,160 - INFO - Loading plugin 'docling_defaults'\n",
            "2025-11-10 01:03:33,163 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3 documents to process\n",
            "Processing: projectOverview.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-10 01:03:33,890 - INFO - Accelerator device: 'mps'\n",
            "2025-11-10 01:05:32,353 - INFO - Accelerator device: 'mps'\n",
            "2025-11-10 01:05:32,784 - INFO - Processing document projectOverview.pdf\n",
            "2025-11-10 01:05:44,769 - INFO - Finished converting document projectOverview.pdf in 131.65 sec.\n",
            "2025-11-10 01:05:44,771 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
            "2025-11-10 01:05:44,772 - INFO - Going to convert document batch...\n",
            "2025-11-10 01:05:44,773 - INFO - Processing document Attention Is All You Need for KV Cache in Diffusion LLMs.pdf\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: Attention Is All You Need for KV Cache in Diffusion LLMs.pdf\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-10 01:05:46,361 - INFO - Finished converting document Attention Is All You Need for KV Cache in Diffusion LLMs.pdf in 1.59 sec.\n",
            "2025-11-10 01:05:46,364 - INFO - detected formats: [<InputFormat.PPTX: 'pptx'>]\n",
            "2025-11-10 01:05:46,372 - INFO - Going to convert document batch...\n",
            "2025-11-10 01:05:46,372 - INFO - Processing document Persona.pptx\n",
            "2025-11-10 01:05:46,425 - INFO - Finished converting document Persona.pptx in 0.06 sec.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: Persona.pptx\n",
            "\n",
            "✓ Batch processing complete! Processed 3 documents\n"
          ]
        }
      ],
      "source": [
        "# Batch processing example\n",
        "# Specify a directory containing multiple documents\n",
        "documents_directory = \"/Users/yashpatil/Developer/AI/SunnySavita/sample\"  # Directory with PDFs, DOCX, PPTX files\n",
        "\n",
        "# Uncomment to process all documents in a directory\n",
        "document_paths = []\n",
        "for ext in ['*.pdf', '*.docx', '*.pptx']:\n",
        "    document_paths.extend(Path(documents_directory).glob(ext))\n",
        "\n",
        "print(f\"Found {len(document_paths)} documents to process\")\n",
        "#\n",
        "# # Process all documents\n",
        "results = []\n",
        "for doc_path in document_paths:\n",
        "    print(f\"Processing: {doc_path.name}\")\n",
        "    result = doc_converter.convert(str(doc_path))\n",
        "    results.append({\n",
        "        'filename': doc_path.name,\n",
        "        'document': result.document\n",
        "    })\n",
        "#\n",
        "print(f\"\\n✓ Batch processing complete! Processed {len(results)} documents\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Document: projectOverview.pdf\n",
            "================================================================================\n",
            "\n",
            "Content Preview:\n",
            "DeepWiki sunnysavita10/document\\_portal\n",
            "\n",
            "## Menu\n",
            "\n",
            "## Document Portal Overview\n",
            "\n",
            "Relevant source files\n",
            "\n",
            "## Purpose and Scope\n",
            "\n",
            "This document provides a high-level introduction to the Document Portal system, a comprehensive document processing platform that combines AI-powered analysis, comparison, and conversational capabilities. The system enables users to upload documents and perform various operations including metadata extraction, document comparison, and interactive question-answering through retrieval-augmented generation (RAG).\n",
            "\n",
            "This overview covers the system's core capabilities, architecture, and technology stack. For detailed setup instructions, see Getting Started . For in-depth architectural details, see System Architecture . For deployment information, see Deployment and Infrastructure .\n",
            "\n",
            "## System Capabilities\n",
            "\n",
            "The Document Portal provides four primary document processing capabilities:\n",
            "\n",
            "| Capability           | Description                                                      | Primary Components                         |\n",
            "|----------------------|------------------------------------------------------------------|--------------------------------------------|\n",
            "| Document Analysis    | Extract structured metadata from single documents using LLMs     | DocumentAnalyzer , DocHandler              |\n",
            "| Document Comparison  | Compare two documents and generate structured comparison results | DocumentComparator , DocumentComparatorLLM |\n",
            "| Single Document Chat | Interactive Q&A with individual documents using RAG              | SingleDocIngestor , ConversationalRAG      |\n",
            "| Multi Document Chat  | Cross-document conversational AI with unified knowledge base     | DocumentIngestor , ConversationalRAG       |\n",
            "\n",
            "The system supports multiple document formats including PDF, DOCX, and TXT files, with\n",
            "\n",
            "Ask Devin about sunnysavita10/document\\_portal processing powered by various LLM providers including Groq and Google GenAI.\n",
            "\n",
            "requirements.txt\n",
            "\n",
            "Sources: Deep Research\n",
            "\n",
            "<!-- image -->\n",
            "\n",
            "1-22\n",
            "\n",
            "README.md\n",
            "\n",
            "41-57\n",
            "\n",
            "Share\n",
            "\n",
            "<!-- image -->\n",
            "\n",
            "<!-- image -->\n",
            "\n",
            "## High-Level Architecture\n",
            "\n",
            "## System Components Overview\n",
            "\n",
            "<!-- image -->\n",
            "\n",
            "Sources:\n",
            "\n",
            "requirements.txt\n",
            "\n",
            "1-22\n",
            "\n",
            "## API Endpoints and Processing Flow\n",
            "\n",
            "Ask Devin about sunnysavita10/document\\_portal\n",
            "\n",
            "Deep Research\n",
            "\n",
            "<!-- image -->\n",
            "\n",
            "<!-- image -->\n",
            "\n",
            "Sources:\n",
            "\n",
            "requirements.txt\n",
            "\n",
            "9-15\n",
            "\n",
            "## Technology Stack\n",
            "\n",
            "The Document Portal is built on a modern AI-first technology stack designed for document processing and conversational AI:\n",
            "\n",
            "## Core Framework Dependencies\n",
            "\n",
            "| Component      | Library   | Version   | Purpose                |\n",
            "|----------------|-----------|-----------|------------------------|\n",
            "| AI Framework   | langchain | 0.3.27    | Core LLM orchestration |\n",
            "| API Backend    | fastapi   | 0.116.1   | REST API services      |\n",
            "| Vector Storage | faiss-cpu | 1.11.0    | Similarity search      |\n",
            "|                | PyMuPDF   |           |                        |\n",
            "\n",
            "Document Processing\n",
            "\n",
            "1.26.3\n",
            "\n",
            "Ask Devin about sunnysavita10/document\\_p\n",
            "...\n",
            "\n",
            "Document Stats:\n",
            "  - Total pages: 5\n",
            "  - Content length: 5305 characters\n",
            "  - Tables: 3\n",
            "  - Pictures: 9\n",
            "\n",
            "================================================================================\n",
            "Document: Attention Is All You Need for KV Cache in Diffusion LLMs.pdf\n",
            "================================================================================\n",
            "\n",
            "Content Preview:\n",
            "Figure 3: Ablation study and analysis of our proposed method. (a) Ablation study of our sliding window mechanism compared to block-wise decoding. (b) Analysis of cache update frequency under varying γ . The blue and orange lines represent accuracy and throughput, respectively. The numbers along the lines indicate the frequency of cache updates, assuming no baseline. (c) Analysis of cache update frequency under confident-aware decoding with varying ϵ .\n",
            "\n",
            "<!-- image -->\n",
            "\n",
            "Table 4: Impact of attention threshold on accuracy and speedup under GSM8K (5-Shot) for LLaDA and LLaDA1.5 with generation length of 512.\n",
            "\n",
            "|           |              |                | Elastic-Cache (Ours)   | Elastic-Cache (Ours)   | Elastic-Cache (Ours)   | Elastic-Cache (Ours)   | Elastic-Cache (Ours)   | Elastic-Cache (Ours)   |\n",
            "|-----------|--------------|----------------|------------------------|------------------------|------------------------|------------------------|------------------------|------------------------|\n",
            "| Model     | No Cache     | Fast-dLLM      | γ = 0 . 5              | γ = 0 . 7              | γ = 0 . 8              | γ = 0 . 85             | γ = 0 . 9              | γ = 0 . 95             |\n",
            "| LLaDA     | 77.10        | 74.83          | 71.57                  | 73.46                  | 74.30                  | 74.68                  | 77.71                  | 76.72                  |\n",
            "|           | 3.6 (1.0 × ) | 44.0 (12.2 × ) | 109.9 (30.5 × )        | 108.7 (30.2 × )        | 103.9 (28.9 × )        | 99.1 (27.5 × )         | 91.5 (25.4 × )         | 75.5 (21.0 × )         |\n",
            "| LLaDA-1.5 | 81.35        | 80.82          | 76.04                  | 77.63                  | 79.45                  | 80.21                  | 81.35                  | 83.02                  |\n",
            "| LLaDA-1.5 | 2.6 (1.0 × ) | 36.8 (14.2 × ) | 142.7 (54.9 × )        | 138.6 (53.3 × )        | 131.2 (50.5 × )        | 129.9 (50.0 × )        | 117.2 (45.1 × )        | 98.4 (37.8 × )         |\n",
            "\n",
            "Table 5: Comparison between Elastic-Cache and Fast-dLLM when varying few-shots and generation length. (a) Impact of few-shots on Accuracy and Speedup Under GSM8K (generation length of 1024) for LLaDA. (b) Impact of generation length on Accuracy and Speedup Under GSM8K (5-Shot), γ = 0 . 8 for LLaDA.\n",
            "\n",
            "| Model.        | 3-shot               | 5-shot               | 8-shot                    | Model.        | 256                         | 512                                     | 1024                      |\n",
            "|---------------|----------------------|----------------------|---------------------------|---------------|-----------------------------|-----------------------------------------|---------------------------|\n",
            "| Fast-dLLM     | 73.77 28.5 (1.0 × )  | 76.04 25.0 (1.0 × )  | 75.36 20.8 (1.0 × ) 75.28 | Fast-dLLM     | 77.94 53.7 (1.0 × ) 78.24 ) | 74.83 44.0 (1.0 × ) 77.71 91.5 (2.1 × ) | 76.04 25.0 (1.0 × ) 75.21 |\n",
            "| Elastic-Cache | 75.13 185.3 (6.5 × ) | 75.21 169.8 (6.8 × ) | 143.9 (6.9 × )            \n",
            "...\n",
            "\n",
            "Document Stats:\n",
            "  - Total pages: 1\n",
            "  - Content length: 5085 characters\n",
            "  - Tables: 2\n",
            "  - Pictures: 1\n",
            "\n",
            "================================================================================\n",
            "Document: Persona.pptx\n",
            "================================================================================\n",
            "\n",
            "Content Preview:\n",
            "Meera Sharma\n",
            "\n",
            "Age: \n",
            "\n",
            "Tech comfort: \n",
            "\n",
            "Hometown: \n",
            "\n",
            "Family: \n",
            "\n",
            "Occupation:\n",
            "\n",
            "29\n",
            "\n",
            "High\n",
            "\n",
            "Delhi\n",
            "\n",
            "Mother of a 2-year-old daughter\n",
            "\n",
            "Marketing Manager\n",
            "\n",
            "“I want the best for my daughter and the planet. If I can find eco-friendly clothes that are both beautiful and sustainable, and make some extra space by reselling them, it's a win-win.”\n",
            "\n",
            "Goals \n",
            "\n",
            "- Wants to purchase eco-friendly and sustainable clothing for her child.\n",
            "- Looking for ways to resell outgrown clothes to make extra money and clear space at home.\n",
            "- Prefers an easy, guided reselling process with minimal hassle.\n",
            "\n",
            "Frustrations \n",
            "\n",
            "- Concerns about the quality and hygiene of second-hand clothes when buying online.\n",
            "- Feels there are limited options for premium eco-friendly clothes in the market.\n",
            "\n",
            "Meera, a marketing manager and mother of a 2-year-old daughter, is passionate about sustainability and wants to ensure that her child wears eco-friendly clothing. She’s already mindful of her family’s environmental footprint and tries to incorporate sustainable practices into her lifestyle.\n",
            "\n",
            "Rajiv Agarwal\n",
            "\n",
            "Age: \n",
            "\n",
            "Tech comfort: \n",
            "\n",
            "Hometown: \n",
            "\n",
            "Family: \n",
            "\n",
            "Occupation:\n",
            "\n",
            "36\n",
            "\n",
            "High\n",
            "\n",
            "Bengaluru\n",
            "\n",
            "Father of a 5-year-old son\n",
            "\n",
            "IT Professional\n",
            "\n",
            "“I believe in getting the best value for my money. Branded clothes for my son should last, and when they don’t fit anymore, I want a simple, safe way to resell them without any hassle.”\n",
            "\n",
            "Goals \n",
            "\n",
            "- Primarily interested in branded and durable children's clothing that lasts longer.\n",
            "- Seeks to resell outgrown clothes as children grow quickly and would like to make extra money.\n",
            "- Prefers a guided reselling process with clear instructions and minimal effort.\n",
            "\n",
            "Frustrations \n",
            "\n",
            "- Worried about the quality and hygiene of second-hand clothes when purchasing for his child.\n",
            "- Finds the reselling process complicated on existing platforms; prefers a simplified approach.\n",
            "- Concerns over the safety and transparency of payment processes\n",
            "- \n",
            "\n",
            "Rajiv, a tech-savvy IT professional and father of a 5-year-old son, wants to buy branded clothes for his son but finds that he quickly outgrows them. He’s interested in finding a platform where he can both buy branded items and easily resell them when his son no longer fits into them.\n",
            "\n",
            "Add image that represents this persona\n",
            "\n",
            "<!-- image -->\n",
            "...\n",
            "\n",
            "Document Stats:\n",
            "  - Total pages: 2\n",
            "  - Content length: 2254 characters\n",
            "  - Tables: 0\n",
            "  - Pictures: 1\n"
          ]
        }
      ],
      "source": [
        "# Extract and display content from all processed documents\n",
        "for result in results:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Document: {result['filename']}\")\n",
        "    print('='*80)\n",
        "    \n",
        "    doc = result['document']\n",
        "    \n",
        "    # Export as markdown for readable content\n",
        "    markdown_content = doc.export_to_markdown()\n",
        "    \n",
        "    # Display first 500 characters of content\n",
        "    print(\"\\nContent Preview:\")\n",
        "    print(markdown_content[:3000])\n",
        "    print(\"...\" if len(markdown_content) > 500 else \"\")\n",
        "    \n",
        "    # Show document statistics\n",
        "    print(f\"\\nDocument Stats:\")\n",
        "    print(f\"  - Total pages: {len(doc.pages) if hasattr(doc, 'pages') else 'N/A'}\")\n",
        "    print(f\"  - Content length: {len(markdown_content)} characters\")\n",
        "    print(f\"  - Tables: {len(doc.tables) if hasattr(doc, 'tables') else 0}\")\n",
        "    print(f\"  - Pictures: {len(doc.pictures) if hasattr(doc, 'pictures') else 0}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Document Parsing and Structure Extraction\n",
        "\n",
        "Once a document is converted, Docling provides structured access to all elements with rich metadata.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export as Markdown\n",
        "\n",
        "Markdown format preserves structure while being human-readable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export document to Markdown format\n",
        "# Uncomment when you have a processed document\n",
        "\n",
        "# markdown_content = doc.export_to_markdown()\n",
        "# print(\"Markdown Export (first 1000 characters):\")\n",
        "# print(\"=\" * 60)\n",
        "# print(markdown_content[:1000])\n",
        "# print(\"=\" * 60)\n",
        "# print(f\"\\nTotal length: {len(markdown_content)} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Export as JSON (Structured)\n",
        "\n",
        "JSON export includes detailed metadata about each element.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export document to JSON format with structure\n",
        "# Uncomment when you have a processed document\n",
        "\n",
        "# json_content = doc.export_to_dict()\n",
        "# \n",
        "# # Pretty print a sample of the JSON structure\n",
        "# print(\"JSON Structure (sample):\")\n",
        "# print(json.dumps(json_content, indent=2, default=str)[:2000])\n",
        "# \n",
        "# # Save to file if needed\n",
        "# # with open('document_structure.json', 'w') as f:\n",
        "# #     json.dump(json_content, f, indent=2, default=str)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Accessing Document Elements\n",
        "\n",
        "Iterate through document elements with metadata like page numbers, element types, and hierarchy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Access document elements with metadata\n",
        "# Uncomment when you have a processed document\n",
        "\n",
        "# print(\"Document Elements Analysis:\")\n",
        "# print(\"=\" * 60)\n",
        "# \n",
        "# # Iterate through document items\n",
        "# for i, (element, level) in enumerate(doc.iterate_items()):\n",
        "#     element_type = type(element).__name__\n",
        "#     text_preview = str(element.text)[:100] if hasattr(element, 'text') else \"\"\n",
        "#     \n",
        "#     # Get page information if available\n",
        "#     page_info = \"\"\n",
        "#     if hasattr(element, 'prov') and element.prov:\n",
        "#         for prov in element.prov:\n",
        "#             if hasattr(prov, 'page_no'):\n",
        "#                 page_info = f\"Page {prov.page_no}\"\n",
        "#                 break\n",
        "#     \n",
        "#     print(f\"[{i}] Type: {element_type:20} Level: {level} {page_info}\")\n",
        "#     if text_preview:\n",
        "#         print(f\"    Text: {text_preview}...\")\n",
        "#     \n",
        "#     if i >= 10:  # Show first 10 elements\n",
        "#         print(f\"\\n... and {len(list(doc.iterate_items())) - 10} more elements\")\n",
        "#         break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting Tables\n",
        "\n",
        "Tables are extracted as structured data, preserving their content and layout.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract and display tables\n",
        "# Uncomment when you have a processed document\n",
        "\n",
        "# from docling_core.types.doc import TableItem\n",
        "# \n",
        "# tables = [item for item, _ in doc.iterate_items() if isinstance(item, TableItem)]\n",
        "# \n",
        "# print(f\"Found {len(tables)} table(s) in the document\\n\")\n",
        "# \n",
        "# for i, table in enumerate(tables[:3]):  # Show first 3 tables\n",
        "#     print(f\"Table {i+1}:\")\n",
        "#     print(\"-\" * 60)\n",
        "#     \n",
        "#     # Export table as markdown\n",
        "#     if hasattr(table, 'export_to_markdown'):\n",
        "#         print(table.export_to_markdown())\n",
        "#     \n",
        "#     # Get table data for pandas\n",
        "#     if hasattr(table, 'data'):\n",
        "#         df = pd.DataFrame(table.data)\n",
        "#         print(df.head())\n",
        "#     \n",
        "#     print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using Docling's HybridChunker\n",
        "\n",
        "The HybridChunker provides intelligent document-aware chunking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ HybridChunker initialized\n",
            "  - Max tokens per chunk: 512\n"
          ]
        }
      ],
      "source": [
        "# Initialize the HybridChunker\n",
        "# Configure chunk size based on your needs\n",
        "# HybridChunker uses a default tokenizer automatically\n",
        "\n",
        "chunker = HybridChunker(\n",
        "    max_tokens=512,  # Maximum tokens per chunk (adjust based on your embedding model)\n",
        ")\n",
        "\n",
        "print(\"✓ HybridChunker initialized\")\n",
        "print(f\"  - Max tokens per chunk: {chunker.max_tokens}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- ### Common Issues and Solutions\n",
        "\n",
        "**Issue: OCR is slow**\n",
        "- Solution: Only enable OCR for scanned documents\n",
        "- Use pipeline options: `pipeline_options.do_ocr = False`\n",
        "\n",
        "**Issue: Tables not extracted properly**\n",
        "- Solution: Use ACCURATE mode and ensure high-quality PDFs\n",
        "- Check table detection: `pipeline_options.do_table_structure = True`\n",
        "\n",
        "**Issue: Chunks too large for embedding model**\n",
        "- Solution: Reduce `max_tokens` in HybridChunker\n",
        "- Verify token count matches your embedding model's limit\n",
        "\n",
        "**Issue: Memory errors with large documents**\n",
        "- Solution: Process documents in smaller batches\n",
        "- Consider processing one document at a time for very large files\n",
        "\n",
        "**Issue: Poor retrieval quality**\n",
        "- Solution: Adjust chunk size and overlap\n",
        "- Ensure metadata is preserved and useful\n",
        "- Consider semantic chunking instead of fixed-size chunks -->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Quick Reference\n",
        "\n",
        "### Minimal Working Example\n",
        "\n",
        "```python\n",
        "# 1. Setup\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling.chunking import HybridChunker\n",
        "\n",
        "# 2. Convert\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"document.pdf\")\n",
        "doc = result.document\n",
        "\n",
        "# 3. Chunk\n",
        "chunker = HybridChunker(max_tokens=512)\n",
        "chunks = list(chunker.chunk(doc))\n",
        "\n",
        "# 4. Use chunks\n",
        "for chunk in chunks:\n",
        "    print(chunk.text)\n",
        "```\n",
        "\n",
        "### Key Parameters Reference\n",
        "\n",
        "**DocumentConverter:**\n",
        "- `do_ocr`: Enable/disable OCR (default: False)\n",
        "- `do_table_structure`: Enable table extraction (default: True)\n",
        "- `table_structure_options.mode`: FAST or ACCURATE\n",
        "\n",
        "**HybridChunker:**\n",
        "- `max_tokens`: Maximum tokens per chunk (default: 512)\n",
        "- Uses a default tokenizer automatically (no need to specify)\n",
        "\n",
        "### Supported Formats\n",
        "\n",
        "- PDF (.pdf)\n",
        "- Microsoft Word (.docx)\n",
        "- PowerPoint (.pptx)\n",
        "- HTML (.html)\n",
        "- Markdown (.md)\n",
        "\n",
        "Check Docling documentation for the complete list.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated a complete workflow for document ingestion and chunking for RAG:\n",
        "\n",
        "1. **Installation & Setup**: Installed Docling and configured the environment\n",
        "2. **Document Ingestion**: Used DocumentConverter to process PDF/DOCX/PPTX files\n",
        "3. **Structure Extraction**: Parsed documents with metadata (pages, sections, tables)\n",
        "4. **Intelligent Chunking**: Split content using HybridChunker with metadata preservation\n",
        "6. **Best Practices**: Covered optimization, troubleshooting, and integration\n",
        "\n",
        "\n",
        "### Resources\n",
        "\n",
        "- **Docling Documentation**: https://github.com/DS4SD/docling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Docling and dependencies\n",
        "# Uncomment and run this cell if you haven't installed these packages yet\n",
        "\n",
        "# !pip install docling\n",
        "# !pip install docling-core\n",
        "# !pip install pandas\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
