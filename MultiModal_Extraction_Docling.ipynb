{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MultiModal Extraction using Docling\n",
        "\n",
        "This notebook demonstrates how to extract multimodal page data (images, text, cells, segments) from documents and export to Parquet format.\n",
        "\n",
        "## Overview\n",
        "\n",
        "**Multimodal extraction** captures rich document information including:\n",
        "- **Page Images**: Rendered page images at configurable resolution\n",
        "- **Text Content**: Plain text and markdown representations\n",
        "- **Cells**: Structured layout cells with bounding boxes\n",
        "- **Segments**: Document segments with hierarchy\n",
        "- **Metadata**: Page dimensions, DPI, hashes, etc.\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "- **Vision-Language Models**: Training data for multimodal LLMs\n",
        "- **Document Understanding**: Combined visual + textual analysis\n",
        "- **Layout Analysis**: Preserve spatial information with content\n",
        "- **Archival**: High-fidelity document preservation\n",
        "- **Dataset Creation**: Build datasets for ML training\n",
        "\n",
        "## Workflow\n",
        "\n",
        "1. Configure PDF pipeline with image generation\n",
        "2. Convert document and extract pages\n",
        "3. Generate multimodal records per page\n",
        "4. Export to Parquet format\n",
        "5. Optional: Load and visualize with HuggingFace Datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Installation and Setup\n",
        "\n",
        "Install required packages for multimodal extraction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "\n",
        "# Uncomment and run if packages are not installed\n",
        "\n",
        "# !pip install docling\n",
        "# !pip install docling-core\n",
        "# !pip install pandas\n",
        "# !pip install pyarrow  # Required for Parquet export\n",
        "# !pip install pillow   # For image handling\n",
        "# !pip install datasets # Optional: for loading Parquet with HuggingFace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yashpatil/Developer/AI/SunnySavita/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import datetime\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Docling imports\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
        "from docling.utils.export import generate_multimodal_pages\n",
        "from docling.utils.utils import create_hash\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "_log = logging.getLogger(__name__)\n",
        "\n",
        "print(\"âœ“ All imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Configure document processing parameters and paths.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration parameters\n",
        "IMAGE_RESOLUTION_SCALE = 2.0  # Image scale: 1.0 = 72 DPI, 2.0 = 144 DPI, etc.\n",
        "\n",
        "# Paths\n",
        "input_doc_path = \"/Users/yashpatil/Developer/AI/SunnySavita/sample/projectOverview.pdf\"  # Change to your document\n",
        "output_dir = Path(\"/Users/yashpatil/Developer/AI/SunnySavita/multimodal_output\")\n",
        "\n",
        "# Create output directory\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  - Input document: {input_doc_path}\")\n",
        "print(f\"  - Output directory: {output_dir}\")\n",
        "print(f\"  - Image resolution scale: {IMAGE_RESOLUTION_SCALE}x (={IMAGE_RESOLUTION_SCALE * 72:.0f} DPI)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize Document Converter with Image Generation\n",
        "\n",
        "Configure the pipeline to generate and preserve page images during conversion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure pipeline options\n",
        "# Key: generate_page_images must be True to export images\n",
        "pipeline_options = PdfPipelineOptions()\n",
        "pipeline_options.images_scale = IMAGE_RESOLUTION_SCALE\n",
        "pipeline_options.generate_page_images = True  # Critical for multimodal export\n",
        "pipeline_options.do_table_structure = True\n",
        "\n",
        "# Initialize converter\n",
        "doc_converter = DocumentConverter(\n",
        "    format_options={\n",
        "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"âœ“ Document converter initialized\")\n",
        "print(f\"  - Page images: ENABLED\")\n",
        "print(f\"  - Image scale: {pipeline_options.images_scale}x\")\n",
        "print(f\"  - Table extraction: {pipeline_options.do_table_structure}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Convert Document\n",
        "\n",
        "Convert the document with image generation enabled.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert document\n",
        "print(f\"Converting document: {input_doc_path}\")\n",
        "print(\"This may take a moment...\")\n",
        "\n",
        "start_time = time.time()\n",
        "conv_res = doc_converter.convert(input_doc_path)\n",
        "conversion_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nâœ“ Document converted in {conversion_time:.2f} seconds\")\n",
        "print(f\"  - Document: {conv_res.input.file.name}\")\n",
        "print(f\"  - Pages: {len(conv_res.document.pages)}\")\n",
        "print(f\"  - Hash: {conv_res.input.document_hash}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Multimodal Records\n",
        "\n",
        "Extract multimodal data (images, text, cells, segments) for each page.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate multimodal records for each page\n",
        "rows = []\n",
        "\n",
        "print(\"Generating multimodal records...\")\n",
        "\n",
        "for (\n",
        "    content_text,      # Plain text content\n",
        "    content_md,        # Markdown content\n",
        "    content_dt,        # DoclingDocument content\n",
        "    page_cells,        # Layout cells\n",
        "    page_segments,     # Document segments\n",
        "    page,              # Page object with image\n",
        ") in generate_multimodal_pages(conv_res):\n",
        "    \n",
        "    # Calculate DPI from scale\n",
        "    dpi = page._default_image_scale * 72\n",
        "    \n",
        "    # Create page record\n",
        "    page_record = {\n",
        "        \"document\": conv_res.input.file.name,\n",
        "        \"hash\": conv_res.input.document_hash,\n",
        "        \"page_hash\": create_hash(\n",
        "            conv_res.input.document_hash + \":\" + str(page.page_no - 1)\n",
        "        ),\n",
        "        \"image\": {\n",
        "            \"width\": page.image.width,\n",
        "            \"height\": page.image.height,\n",
        "            \"bytes\": page.image.tobytes(),\n",
        "        },\n",
        "        \"cells\": page_cells,\n",
        "        \"contents\": content_text,\n",
        "        \"contents_md\": content_md,\n",
        "        \"contents_dt\": content_dt,\n",
        "        \"segments\": page_segments,\n",
        "        \"extra\": {\n",
        "            \"page_num\": page.page_no,\n",
        "            \"width_in_points\": page.size.width,\n",
        "            \"height_in_points\": page.size.height,\n",
        "            \"dpi\": dpi,\n",
        "        },\n",
        "    }\n",
        "    \n",
        "    rows.append(page_record)\n",
        "    print(f\"  âœ“ Page {page.page_no}: {page.image.width}x{page.image.height}px @ {dpi:.0f} DPI\")\n",
        "\n",
        "print(f\"\\nâœ“ Generated {len(rows)} multimodal page records\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Create DataFrame and Export to Parquet\n",
        "\n",
        "Convert records to a pandas DataFrame and save as Parquet file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert to DataFrame with flattened structure\n",
        "df_result = pd.json_normalize(rows)\n",
        "\n",
        "# Generate timestamped filename\n",
        "now = datetime.datetime.now()\n",
        "output_filename = output_dir / f\"multimodal_{now:%Y-%m-%d_%H%M%S}.parquet\"\n",
        "\n",
        "# Export to Parquet\n",
        "df_result.to_parquet(output_filename, engine='pyarrow')\n",
        "\n",
        "print(f\"âœ“ Multimodal data exported to Parquet\")\n",
        "print(f\"  - File: {output_filename}\")\n",
        "print(f\"  - Size: {output_filename.stat().st_size / 1024:.2f} KB\")\n",
        "print(f\"  - Records: {len(df_result)}\")\n",
        "print(f\"\\nDataFrame shape: {df_result.shape}\")\n",
        "print(f\"Columns: {list(df_result.columns)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Inspect the Data\n",
        "\n",
        "Preview the extracted multimodal data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display DataFrame info\n",
        "print(\"DataFrame Information:\")\n",
        "print(\"=\" * 80)\n",
        "print(df_result.info())\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Sample Data (first row):\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Show first record (excluding image bytes for readability)\n",
        "sample = df_result.iloc[0].to_dict()\n",
        "for key, value in sample.items():\n",
        "    if key == 'image.bytes':\n",
        "        print(f\"{key}: <binary data, {len(value)} bytes>\")\n",
        "    elif isinstance(value, str) and len(value) > 200:\n",
        "        print(f\"{key}: {value[:200]}...\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Text Content Preview\n",
        "\n",
        "Display text content from the first few pages.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview text content from first 2 pages\n",
        "num_pages_to_show = min(2, len(df_result))\n",
        "\n",
        "for i in range(num_pages_to_show):\n",
        "    row = df_result.iloc[i]\n",
        "    print(f\"\\n{'=' * 80}\")\n",
        "    print(f\"Page {row['extra.page_num']}\")\n",
        "    print(f\"{'=' * 80}\")\n",
        "    print(f\"Dimensions: {row['extra.width_in_points']:.1f} x {row['extra.height_in_points']:.1f} points\")\n",
        "    print(f\"Image: {row['image.width']}x{row['image.height']}px @ {row['extra.dpi']:.0f} DPI\")\n",
        "    print(f\"\\nText Content (first 500 chars):\")\n",
        "    print(\"-\" * 80)\n",
        "    content = row['contents']\n",
        "    print(content[:500] if len(content) > 500 else content)\n",
        "    if len(content) > 500:\n",
        "        print(\"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "otebook "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Load with HuggingFace Datasets and reconstruct images\n",
        "# Uncomment to run (requires: pip install datasets pillow)\n",
        "\n",
        "# from datasets import Dataset\n",
        "# from PIL import Image\n",
        "# import io\n",
        "# \n",
        "# # Load the Parquet file\n",
        "# multimodal_df = pd.read_parquet(output_filename)\n",
        "# \n",
        "# # Convert to HuggingFace Dataset\n",
        "# dataset = Dataset.from_pandas(multimodal_df)\n",
        "# \n",
        "# # Function to reconstruct images from bytes\n",
        "# def reconstruct_image(example):\n",
        "#     \"\"\"Reconstruct PIL Image from raw bytes.\"\"\"\n",
        "#     img = Image.frombytes(\n",
        "#         'RGB',\n",
        "#         (example[\"image.width\"], example[\"image.height\"]),\n",
        "#         example[\"image.bytes\"],\n",
        "#         'raw'\n",
        "#     )\n",
        "#     example[\"reconstructed_image\"] = img\n",
        "#     return example\n",
        "# \n",
        "# # Apply transformation\n",
        "# dataset = dataset.map(reconstruct_image)\n",
        "# \n",
        "# print(\"âœ“ Dataset loaded with reconstructed images\")\n",
        "# print(f\"  - Records: {len(dataset)}\")\n",
        "# print(f\"  - Features: {dataset.features}\")\n",
        "# \n",
        "# # Display first image\n",
        "# first_record = dataset[0]\n",
        "# print(f\"\\nFirst page image: {first_record['reconstructed_image'].size}\")\n",
        "# first_record['reconstructed_image'].show()  # Opens image viewer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Complete Pipeline Function\n",
        "\n",
        "A reusable function to process any document and export multimodal data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Visualize Page Images (Alternative)\n",
        "\n",
        "Display page images directly from the extracted data using matplotlib.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example: Use the Pipeline Function\n",
        "\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize page images using matplotlib\n",
        "# Uncomment to display images\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# from PIL import Image\n",
        "# import io\n",
        "# \n",
        "# # Number of pages to visualize\n",
        "# num_pages = min(3, len(df_result))\n",
        "# \n",
        "# fig, axes = plt.subplots(1, num_pages, figsize=(15, 5))\n",
        "# if num_pages == 1:\n",
        "#     axes = [axes]\n",
        "# \n",
        "# for i in range(num_pages):\n",
        "#     row = df_result.iloc[i]\n",
        "#     \n",
        "#     # Reconstruct image from bytes\n",
        "#     img = Image.frombytes(\n",
        "#         'RGB',\n",
        "#         (row['image.width'], row['image.height']),\n",
        "#         row['image.bytes'],\n",
        "#         'raw'\n",
        "#     )\n",
        "#     \n",
        "#     # Display\n",
        "#     axes[i].imshow(img)\n",
        "#     axes[i].set_title(f\"Page {row['extra.page_num']}\\n{row['image.width']}x{row['image.height']}px\")\n",
        "#     axes[i].axis('off')\n",
        "# \n",
        "# plt.tight_layout()\n",
        "# plt.show()\n",
        "# \n",
        "# print(f\"âœ“ Displayed {num_pages} page images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Use Cases and Applications\n",
        "\n",
        "### Training Vision-Language Models (VLMs)\n",
        "\n",
        "The exported Parquet files are ideal for training multimodal models:\n",
        "\n",
        "```python\n",
        "# Load as HuggingFace dataset for training\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('parquet', data_files='multimodal_*.parquet')\n",
        "\n",
        "# Use with PyTorch DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
        "```\n",
        "\n",
        "### Document Understanding Pipeline\n",
        "\n",
        "Combine visual and textual features:\n",
        "\n",
        "```python\n",
        "# Extract features for each page\n",
        "for page in dataset:\n",
        "    image = page['reconstructed_image']\n",
        "    text = page['contents']\n",
        "    cells = page['cells']\n",
        "    \n",
        "    # Process with vision model\n",
        "    visual_features = vision_model(image)\n",
        "    \n",
        "    # Process with language model\n",
        "    text_features = language_model(text)\n",
        "    \n",
        "    # Combine for downstream tasks\n",
        "    combined_features = combine(visual_features, text_features)\n",
        "```\n",
        "\n",
        "### Document Archival System\n",
        "\n",
        "Preserve documents with high fidelity:\n",
        "- Full-resolution page images\n",
        "- Structured text content\n",
        "- Layout information (cells, segments)\n",
        "- Searchable metadata\n",
        "\n",
        "### Advantages\n",
        "\n",
        "- **Efficient Storage**: Parquet format with compression\n",
        "- **Fast Access**: Columnar format for quick queries\n",
        "- **Rich Metadata**: Complete document structure preserved\n",
        "- **ML-Ready**: Direct integration with ML frameworks\n",
        "- **Scalable**: Process batches of documents efficiently\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_multimodal_document(\n",
        "    input_path: str,\n",
        "    output_dir: Path,\n",
        "    image_scale: float = 2.0,\n",
        "    include_tables: bool = True\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Convert a document and export multimodal page data to Parquet.\n",
        "    \n",
        "    Args:\n",
        "        input_path: Path to input document (PDF, DOCX, etc.)\n",
        "        output_dir: Directory to save Parquet file\n",
        "        image_scale: Image resolution scale (1.0 = 72 DPI)\n",
        "        include_tables: Enable table structure extraction\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with export info and file path\n",
        "    \"\"\"\n",
        "    # Configure pipeline\n",
        "    pipeline_options = PdfPipelineOptions()\n",
        "    pipeline_options.images_scale = image_scale\n",
        "    pipeline_options.generate_page_images = True\n",
        "    pipeline_options.do_table_structure = include_tables\n",
        "    \n",
        "    # Initialize converter\n",
        "    doc_converter = DocumentConverter(\n",
        "        format_options={\n",
        "            InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    # Convert document\n",
        "    print(f\"Converting: {input_path}\")\n",
        "    start_time = time.time()\n",
        "    conv_res = doc_converter.convert(input_path)\n",
        "    \n",
        "    # Generate multimodal records\n",
        "    rows = []\n",
        "    for (content_text, content_md, content_dt, page_cells, \n",
        "         page_segments, page) in generate_multimodal_pages(conv_res):\n",
        "        \n",
        "        dpi = page._default_image_scale * 72\n",
        "        rows.append({\n",
        "            \"document\": conv_res.input.file.name,\n",
        "            \"hash\": conv_res.input.document_hash,\n",
        "            \"page_hash\": create_hash(\n",
        "                conv_res.input.document_hash + \":\" + str(page.page_no - 1)\n",
        "            ),\n",
        "            \"image\": {\n",
        "                \"width\": page.image.width,\n",
        "                \"height\": page.image.height,\n",
        "                \"bytes\": page.image.tobytes(),\n",
        "            },\n",
        "            \"cells\": page_cells,\n",
        "            \"contents\": content_text,\n",
        "            \"contents_md\": content_md,\n",
        "            \"contents_dt\": content_dt,\n",
        "            \"segments\": page_segments,\n",
        "            \"extra\": {\n",
        "                \"page_num\": page.page_no,\n",
        "                \"width_in_points\": page.size.width,\n",
        "                \"height_in_points\": page.size.height,\n",
        "                \"dpi\": dpi,\n",
        "            },\n",
        "        })\n",
        "    \n",
        "    # Create DataFrame and export\n",
        "    df_result = pd.json_normalize(rows)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    now = datetime.datetime.now()\n",
        "    output_filename = output_dir / f\"multimodal_{now:%Y-%m-%d_%H%M%S}.parquet\"\n",
        "    df_result.to_parquet(output_filename, engine='pyarrow')\n",
        "    \n",
        "    elapsed = time.time() - start_time\n",
        "    \n",
        "    return {\n",
        "        \"input_path\": input_path,\n",
        "        \"output_file\": str(output_filename),\n",
        "        \"num_pages\": len(rows),\n",
        "        \"file_size_kb\": output_filename.stat().st_size / 1024,\n",
        "        \"processing_time\": elapsed,\n",
        "        \"image_dpi\": image_scale * 72,\n",
        "    }\n",
        "\n",
        "print(\"âœ“ Multimodal export function defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage of the pipeline function\n",
        "# Uncomment to process a document\n",
        "\n",
        "# result = export_multimodal_document(\n",
        "#     input_path=\"/path/to/your/document.pdf\",\n",
        "#     output_dir=Path(\"multimodal_output\"),\n",
        "#     image_scale=2.0,  # 144 DPI\n",
        "#     include_tables=True\n",
        "# )\n",
        "# \n",
        "# print(\"\\nExport Complete!\")\n",
        "# print(f\"  - Output file: {result['output_file']}\")\n",
        "# print(f\"  - Pages processed: {result['num_pages']}\")\n",
        "# print(f\"  - File size: {result['file_size_kb']:.2f} KB\")\n",
        "# print(f\"  - Processing time: {result['processing_time']:.2f} seconds\")\n",
        "# print(f\"  - Image DPI: {result['image_dpi']:.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "de "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Setup**: Configured Docling with image generation enabled\n",
        "2. **Conversion**: Processed document with multimodal extraction\n",
        "3. **Data Generation**: Created per-page records with images, text, cells, and segments\n",
        "4. **Export**: Saved to Parquet format for efficient storage\n",
        "5. **Loading**: Showed how to load and reconstruct data with HuggingFace Datasets\n",
        "6. **Visualization**: Displayed page images and content\n",
        "7. **Pipeline**: Created reusable function for batch processing\n",
        "\n",
        "### Key Parameters\n",
        "\n",
        "- **`images_scale`**: Controls image resolution (1.0 = 72 DPI, 2.0 = 144 DPI)\n",
        "- **`generate_page_images`**: Must be `True` for multimodal export\n",
        "- **Output format**: Parquet with flattened JSON structure\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Process multiple documents in batch\n",
        "- Integrate with ML training pipelines\n",
        "- Build custom visualization tools\n",
        "- Create document search and retrieval systems\n",
        "- Train vision-language models on extracted data\n",
        "\n",
        "### Resources\n",
        "\n",
        "- **Docling Documentation**: https://github.com/DS4SD/docling\n",
        "- **Parquet Format**: https://parquet.apache.org/\n",
        "- **HuggingFace Datasets**: https://huggingface.co/docs/datasets/\n",
        "\n",
        "---\n",
        "\n",
        "**Ready for multimodal document processing! ðŸš€**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
