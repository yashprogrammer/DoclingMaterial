{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ASR using Whisper in Docling\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to build an **Automatic Speech Recognition (ASR)** pipeline using **Whisper** models with **Docling**.\n",
        "\n",
        "### What is ASR?\n",
        "\n",
        "**Automatic Speech Recognition (ASR)** is the technology that converts spoken language into written text. It's the foundation of voice assistants, transcription services, and accessibility tools.\n",
        "\n",
        "### What is Whisper?\n",
        "\n",
        "**Whisper** is a state-of-the-art ASR model developed by OpenAI. It's trained on 680,000 hours of multilingual data and can:\n",
        "- Transcribe speech in multiple languages\n",
        "- Handle noisy audio\n",
        "- Provide accurate timestamps\n",
        "- Work across different accents and speaking styles\n",
        "\n",
        "### What is Docling?\n",
        "\n",
        "**Docling** is a powerful document processing library that supports multiple input formats, including audio files. It provides a unified pipeline for converting various document types into structured formats.\n",
        "\n",
        "---\n",
        "\n",
        "## What This Notebook Does\n",
        "\n",
        "This notebook will:\n",
        "1. Configure an ASR pipeline with Whisper Turbo model\n",
        "2. Convert an audio file to text\n",
        "3. Export the transcription to Markdown with timestamps\n",
        "4. Demonstrate automatic model selection based on your hardware\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prerequisites\n",
        "\n",
        "Before running this notebook, you need to:\n",
        "\n",
        "1. **Install Docling with ASR extras:**\n",
        "   ```bash\n",
        "   pip install docling[asr]\n",
        "   ```\n",
        "\n",
        "2. **Install ffmpeg** (required for audio processing):\n",
        "   - **macOS:** `brew install ffmpeg`\n",
        "   - **Ubuntu/Debian:** `sudo apt-get install ffmpeg`\n",
        "   - **Windows:** Download from [ffmpeg.org](https://ffmpeg.org/download.html)\n",
        "\n",
        "3. **Optional - For Apple Silicon (M1/M2/M3):**\n",
        "   ```bash\n",
        "   pip install mlx-whisper\n",
        "   ```\n",
        "   This will enable faster inference using MLX optimization.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Required Libraries\n",
        "\n",
        "Let's import all the necessary modules for our ASR pipeline:\n",
        "\n",
        "- **`pathlib.Path`**: For handling file paths in a cross-platform way\n",
        "- **`docling_core.types.doc.DoclingDocument`**: The document object that stores transcriptions\n",
        "- **`docling.datamodel.asr_model_specs`**: Pre-configured ASR model specifications\n",
        "- **`docling.datamodel`**: Data models for conversion status and input formats\n",
        "- **`docling.document_converter`**: Main converter class for processing audio files\n",
        "- **`docling.pipeline.asr_pipeline`**: The ASR-specific pipeline implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "from docling_core.types.doc import DoclingDocument\n",
        "from docling.datamodel import asr_model_specs\n",
        "from docling.datamodel.base_models import ConversionStatus, InputFormat\n",
        "from docling.datamodel.document import ConversionResult\n",
        "from docling.datamodel.pipeline_options import AsrPipelineOptions\n",
        "from docling.document_converter import AudioFormatOption, DocumentConverter\n",
        "from docling.pipeline.asr_pipeline import AsrPipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create the ASR Converter\n",
        "\n",
        "This function creates and configures a `DocumentConverter` specifically for ASR tasks.\n",
        "\n",
        "### Key Components:\n",
        "\n",
        "1. **`AsrPipelineOptions()`**: Configuration object for the ASR pipeline\n",
        "2. **`asr_model_specs.WHISPER_TURBO`**: Automatic model selection:\n",
        "   - Uses **MLX Whisper Turbo** on Apple Silicon (faster, optimized for M-series chips)\n",
        "   - Falls back to **Native Whisper Turbo** on other hardware\n",
        "3. **`AudioFormatOption`**: Specifies:\n",
        "   - `pipeline_cls`: Which pipeline to use (AsrPipeline)\n",
        "   - `pipeline_options`: Configuration for the pipeline\n",
        "\n",
        "### Available Models:\n",
        "\n",
        "You can swap `WHISPER_TURBO` with other models from `asr_model_specs`:\n",
        "- `WHISPER_TINY`: Smallest, fastest, less accurate\n",
        "- `WHISPER_BASE`: Balanced for speed and accuracy\n",
        "- `WHISPER_SMALL`: Good accuracy, moderate speed\n",
        "- `WHISPER_MEDIUM`: High accuracy, slower\n",
        "- `WHISPER_LARGE`: Highest accuracy, slowest\n",
        "- `WHISPER_TURBO`: Optimized version, good balance (recommended)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_asr_converter():\n",
        "    \"\"\"Create a DocumentConverter configured for ASR with automatic model selection.\n",
        "\n",
        "    Uses `asr_model_specs.WHISPER_TURBO` which automatically selects the best\n",
        "    implementation for your hardware:\n",
        "    - MLX Whisper Turbo for Apple Silicon (M1/M2/M3) with mlx-whisper installed\n",
        "    - Native Whisper Turbo as fallback\n",
        "\n",
        "    You can swap in another model spec from `docling.datamodel.asr_model_specs`\n",
        "    to experiment with different model sizes.\n",
        "    \"\"\"\n",
        "    # Create pipeline options\n",
        "    pipeline_options = AsrPipelineOptions()\n",
        "    \n",
        "    # Set the ASR model (Whisper Turbo with automatic hardware selection)\n",
        "    pipeline_options.asr_options = asr_model_specs.WHISPER_TURBO\n",
        "\n",
        "    # Create the document converter with audio format support\n",
        "    converter = DocumentConverter(\n",
        "        format_options={\n",
        "            InputFormat.AUDIO: AudioFormatOption(\n",
        "                pipeline_cls=AsrPipeline,\n",
        "                pipeline_options=pipeline_options,\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    return converter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Define the ASR Pipeline Conversion Function\n",
        "\n",
        "This function performs the actual transcription:\n",
        "\n",
        "### Process Flow:\n",
        "\n",
        "1. **Validate**: Check if the audio file exists\n",
        "2. **Initialize**: Get the configured converter\n",
        "3. **Convert**: Process the audio file through the ASR pipeline\n",
        "4. **Verify**: Ensure the conversion was successful\n",
        "5. **Return**: Return the `DoclingDocument` containing the transcription\n",
        "\n",
        "### Return Value:\n",
        "\n",
        "The function returns a `DoclingDocument` object that contains:\n",
        "- Transcribed text segments\n",
        "- Timestamps for each segment\n",
        "- Metadata about the conversion\n",
        "\n",
        "This document can be exported to various formats (Markdown, JSON, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def asr_pipeline_conversion(audio_path: Path) -> DoclingDocument:\n",
        "    \"\"\"Run the ASR pipeline and return a `DoclingDocument` transcript.\"\"\"\n",
        "    \n",
        "    # Check if the audio file exists\n",
        "    assert audio_path.exists(), f\"Audio file not found: {audio_path}\"\n",
        "    \n",
        "    # Get the configured ASR converter\n",
        "    converter = get_asr_converter()\n",
        "\n",
        "    # Convert the audio file to text\n",
        "    print(f\"Converting audio file: {audio_path}\")\n",
        "    result: ConversionResult = converter.convert(audio_path)\n",
        "\n",
        "    # Verify conversion was successful\n",
        "    assert result.status == ConversionStatus.SUCCESS, (\n",
        "        f\"Conversion failed with status: {result.status}\"\n",
        "    )\n",
        "    \n",
        "    print(\"Conversion successful!\")\n",
        "    return result.document\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Run the ASR Pipeline\n",
        "\n",
        "Now let's transcribe an audio file!\n",
        "\n",
        "### Input Audio:\n",
        "\n",
        "The default example uses `tests/data/audio/sample_10s.mp3` from Docling's test suite.\n",
        "\n",
        "**To use your own audio file:**\n",
        "1. Replace the path below with your audio file path\n",
        "2. Supported formats: MP3, WAV, FLAC, M4A, OGG, and more (via ffmpeg)\n",
        "\n",
        "Example:\n",
        "```python\n",
        "audio_path = Path(\"path/to/your/audio.mp3\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the path to your audio file\n",
        "# Default: uses Docling's test audio file\n",
        "audio_path = Path(\"tests/data/audio/sample_10s.mp3\")\n",
        "\n",
        "# Uncomment and modify this line to use your own audio file:\n",
        "# audio_path = Path(\"your_audio_file.mp3\")\n",
        "\n",
        "# Run the ASR pipeline\n",
        "doc = asr_pipeline_conversion(audio_path=audio_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: View the Transcription\n",
        "\n",
        "Let's export and display the transcription in Markdown format.\n",
        "\n",
        "### Output Format:\n",
        "\n",
        "The output includes:\n",
        "- **Timestamps**: `[time: start-end]` showing when each segment was spoken\n",
        "- **Text**: The transcribed speech\n",
        "\n",
        "### Expected Output:\n",
        "\n",
        "For the sample audio file, you should see something like:\n",
        "\n",
        "```\n",
        "[time: 0.0-4.0]  Shakespeare on Scenery by Oscar Wilde\n",
        "\n",
        "[time: 5.28-9.96]  This is a LibriVox recording. All LibriVox recordings are in the public domain.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the document to Markdown format\n",
        "transcription = doc.export_to_markdown()\n",
        "\n",
        "# Display the transcription\n",
        "print(\"\\n=== Transcription ===\")\n",
        "print(transcription)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Explore the Document Object\n",
        "\n",
        "The `DoclingDocument` object contains rich information about the transcription.\n",
        "\n",
        "Let's explore its structure:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display document type\n",
        "print(f\"Document Type: {type(doc)}\")\n",
        "\n",
        "# Display document name (if available)\n",
        "if hasattr(doc, 'name'):\n",
        "    print(f\"Document Name: {doc.name}\")\n",
        "\n",
        "# You can also export to JSON for more detailed structure\n",
        "print(\"\\n=== Document as JSON (first 500 chars) ===\")\n",
        "json_output = doc.export_to_json()\n",
        "print(json_output[:500] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Customization Options\n",
        "\n",
        "### 1. Using Different Whisper Models\n",
        "\n",
        "You can experiment with different model sizes to balance speed and accuracy:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Processing Multiple Audio Files\n",
        "\n",
        "You can process multiple audio files in a batch:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_custom_asr_converter(model_spec):\n",
        "    \"\"\"Create a converter with a custom model specification.\"\"\"\n",
        "    pipeline_options = AsrPipelineOptions()\n",
        "    pipeline_options.asr_options = model_spec\n",
        "    \n",
        "    converter = DocumentConverter(\n",
        "        format_options={\n",
        "            InputFormat.AUDIO: AudioFormatOption(\n",
        "                pipeline_cls=AsrPipeline,\n",
        "                pipeline_options=pipeline_options,\n",
        "            )\n",
        "        }\n",
        "    )\n",
        "    return converter\n",
        "\n",
        "# Example usage (commented out to avoid running):\n",
        "# converter_tiny = get_custom_asr_converter(asr_model_specs.WHISPER_TINY)\n",
        "# converter_large = get_custom_asr_converter(asr_model_specs.WHISPER_LARGE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "1. **Simple Setup**: Docling provides a straightforward API for ASR tasks\n",
        "2. **Hardware Optimization**: Automatic model selection based on your hardware (MLX for Apple Silicon)\n",
        "3. **Multiple Formats**: Supports various audio formats through ffmpeg\n",
        "4. **Timestamped Output**: Includes precise timing information for each speech segment\n",
        "5. **Flexible Export**: Can export to Markdown, JSON, or other formats\n",
        "6. **Model Options**: Choose from multiple Whisper model sizes based on your needs\n",
        "\n",
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "- Try transcribing your own audio files\n",
        "- Experiment with different Whisper models\n",
        "- Process multiple files in batch\n",
        "- Integrate with other Docling features for document processing\n",
        "- Explore multilingual transcription capabilities\n",
        "\n",
        "---\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [Docling Documentation](https://github.com/DS4SD/docling)\n",
        "- [Whisper by OpenAI](https://github.com/openai/whisper)\n",
        "- [MLX Whisper for Apple Silicon](https://github.com/ml-explore/mlx-examples/tree/main/whisper)\n",
        "- [FFmpeg Download](https://ffmpeg.org/download.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "terial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_transcribe(audio_files: list[Path]) -> dict[str, str]:\n",
        "    \"\"\"Transcribe multiple audio files and return a dictionary of results.\"\"\"\n",
        "    converter = get_asr_converter()\n",
        "    results = {}\n",
        "    \n",
        "    for audio_path in audio_files:\n",
        "        if not audio_path.exists():\n",
        "            print(f\"Warning: File not found - {audio_path}\")\n",
        "            continue\n",
        "            \n",
        "        try:\n",
        "            result = converter.convert(audio_path)\n",
        "            if result.status == ConversionStatus.SUCCESS:\n",
        "                results[str(audio_path)] = result.document.export_to_markdown()\n",
        "            else:\n",
        "                print(f\"Failed to convert: {audio_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {audio_path}: {e}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Example usage (commented out):\n",
        "# audio_files = [\n",
        "#     Path(\"audio1.mp3\"),\n",
        "#     Path(\"audio2.mp3\"),\n",
        "#     Path(\"audio3.mp3\"),\n",
        "# ]\n",
        "# transcriptions = batch_transcribe(audio_files)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "al"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
